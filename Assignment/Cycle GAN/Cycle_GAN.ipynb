{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n_Xp-tzgQxAK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, LeakyReLU, Dropout, Flatten, Dense, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = (X_train.astype(np.float32) / 127.5) - 1.0  # [-1, 1]\n",
        "X_train = np.expand_dims(X_train, axis=-1)  # (28,28,1)\n",
        "\n",
        "# Two domains: A (original), B (inverted)\n",
        "X_A = X_train\n",
        "X_B = -X_train\n",
        "\n",
        "img_shape = (28,28,1)\n",
        "latent_dim = 100\n",
        "optimizer = Adam(0.0002, 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYYSCdtgSff6",
        "outputId": "b4bc8258-fc1d-4078-9528-20dcfb6d3754"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(img_shape):\n",
        "    inputs = Input(shape=img_shape)\n",
        "\n",
        "    x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2DTranspose(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    outputs = Conv2D(1, kernel_size=3, padding=\"same\", activation=\"tanh\")(x)\n",
        "    return Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "VO1LeXdvSgQ0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape):\n",
        "    img = Input(shape=img_shape)\n",
        "\n",
        "    x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(img)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    validity = Dense(1, activation=\"sigmoid\")(x)\n",
        "    return Model(img, validity)"
      ],
      "metadata": {
        "id": "t8I-M0VWSjQk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_AB = build_generator(img_shape)\n",
        "G_BA = build_generator(img_shape)\n",
        "\n",
        "D_A = build_discriminator(img_shape)\n",
        "D_B = build_discriminator(img_shape)\n",
        "\n",
        "D_A.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "D_B.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "v6yunRrjSmn3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_A = Input(shape=img_shape)\n",
        "img_B = Input(shape=img_shape)\n",
        "\n",
        "fake_B = G_AB(img_A)\n",
        "fake_A = G_BA(img_B)\n",
        "\n",
        "reconstr_A = G_BA(fake_B)\n",
        "reconstr_B = G_AB(fake_A)\n",
        "\n",
        "img_A_id = G_BA(img_A)\n",
        "img_B_id = G_AB(img_B)\n",
        "\n",
        "D_A.trainable = False\n",
        "D_B.trainable = False\n",
        "\n",
        "valid_A = D_A(fake_A)\n",
        "valid_B = D_B(fake_B)\n",
        "\n",
        "combined = Model(inputs=[img_A, img_B],\n",
        "                 outputs=[valid_A, valid_B,\n",
        "                          reconstr_A, reconstr_B,\n",
        "                          img_A_id, img_B_id])\n",
        "\n",
        "combined.compile(loss=[\"mse\", \"mse\", \"mae\", \"mae\", \"mae\", \"mae\"],\n",
        "                 loss_weights=[1,1,10,10,1,1],\n",
        "                 optimizer=optimizer)"
      ],
      "metadata": {
        "id": "TiRgy_ZVSpAQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs=10000, batch_size=64, save_interval=1000):\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    d_losses, g_losses = [], []\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        idx = np.random.randint(0, X_A.shape[0], batch_size)\n",
        "        imgs_A = X_A[idx]\n",
        "        imgs_B = X_B[idx]\n",
        "\n",
        "        fake_B = G_AB.predict(imgs_A, verbose=0)\n",
        "        fake_A = G_BA.predict(imgs_B, verbose=0)\n",
        "\n",
        "        dA_loss_real = D_A.train_on_batch(imgs_A, valid)\n",
        "        dA_loss_fake = D_A.train_on_batch(fake_A, fake)\n",
        "        dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "        dB_loss_real = D_B.train_on_batch(imgs_B, valid)\n",
        "        dB_loss_fake = D_B.train_on_batch(fake_B, fake)\n",
        "        dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "        d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "\n",
        "        g_loss = combined.train_on_batch([imgs_A, imgs_B],\n",
        "                                         [valid, valid, imgs_A, imgs_B, imgs_A, imgs_B])\n",
        "\n",
        "        d_losses.append(d_loss[0])\n",
        "        g_losses.append(g_loss[0])\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"{epoch} [D loss: {d_loss[0]:.4f}, acc: {100*d_loss[1]:.2f}] [G loss: {g_loss[0]:.4f}]\")\n",
        "\n",
        "        if epoch % save_interval == 0:\n",
        "            save_imgs(epoch)\n",
        "\n",
        "    return d_losses, g_losses\n"
      ],
      "metadata": {
        "id": "HJI3-jm_Sp0C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_imgs(epoch, examples=5):\n",
        "    idx = np.random.randint(0, X_A.shape[0], examples)\n",
        "    imgs_A = X_A[idx]\n",
        "    imgs_B = X_B[idx]\n",
        "\n",
        "    fake_B = G_AB.predict(imgs_A, verbose=0)\n",
        "    fake_A = G_BA.predict(imgs_B, verbose=0)\n",
        "\n",
        "    gen_imgs = np.concatenate([imgs_A, fake_B, imgs_B, fake_A])\n",
        "\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    titles = [\"A\", \"A→B\", \"B\", \"B→A\"]\n",
        "    plt.figure(figsize=(10,4))\n",
        "    for i in range(examples*4):\n",
        "        plt.subplot(examples, 4, i+1)\n",
        "        plt.imshow(gen_imgs[i,:,:,0], cmap=\"gray\")\n",
        "        plt.title(titles[i%4])\n",
        "        plt.axis(\"off\")\n",
        "    plt.suptitle(f\"Epoch {epoch}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4OSRzdeiSsq_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_losses, g_losses = train(epochs=2000, batch_size=64, save_interval=500)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(d_losses, label=\"Discriminator Loss\")\n",
        "plt.plot(g_losses, label=\"Generator Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"CycleGAN Training Losses\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUuvM9b0SvDh",
        "outputId": "aa801324-6d16-4db6-ebab-945178224e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py:83: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 [D loss: 0.2555, acc: 37.65] [G loss: 8.5332]\n"
          ]
        }
      ]
    }
  ]
}